{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The notebook is divided into 3 parts:\n",
    "- In the first part we import the images and create the dataframe\n",
    "- In the second part we define our embedding network and train it on the given images\n",
    "- In the last part we use the embedding network to create a classifier and use it to classify the given images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Data import and dataframe creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing important libraries for the section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rather than importing all the images together, we shall create a dataframe with Image path and respective label \"string type\", and then encode the labels \"numeral type\". This makes the execution faster by only importing selected images at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                            Images     Labels\n",
       "0  /train/Sample029/img029-019.png  Sample029\n",
       "1  /train/Sample029/img029-028.png  Sample029\n",
       "2  /train/Sample029/img029-051.png  Sample029\n",
       "3  /train/Sample029/img029-023.png  Sample029\n",
       "4  /train/Sample029/img029-040.png  Sample029"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Images</th>\n      <th>Labels</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>/train/Sample029/img029-019.png</td>\n      <td>Sample029</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>/train/Sample029/img029-028.png</td>\n      <td>Sample029</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>/train/Sample029/img029-051.png</td>\n      <td>Sample029</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>/train/Sample029/img029-023.png</td>\n      <td>Sample029</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>/train/Sample029/img029-040.png</td>\n      <td>Sample029</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "imagePath = []\n",
    "labels = []\n",
    "for folder in os.listdir('./train'):\n",
    "    for images in os.listdir(os.path.join('./train/',folder)):\n",
    "        image = os.path.join('/train/',folder,images)\n",
    "        imagePath.append(image)\n",
    "        labels.append(folder)\n",
    "data = {'Images':imagePath, 'Labels':labels}\n",
    "data = pd.DataFrame(data)\n",
    "data.head()"
   ]
  },
  {
   "source": [
    "Now that  we have the Image path and their respective labels, we shall encode these labels to their numerical counterparts for our deep learning model."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                            Images     Labels  Encoded Labels\n",
       "0  /train/Sample029/img029-019.png  Sample029              28\n",
       "1  /train/Sample029/img029-028.png  Sample029              28\n",
       "2  /train/Sample029/img029-051.png  Sample029              28\n",
       "3  /train/Sample029/img029-023.png  Sample029              28\n",
       "4  /train/Sample029/img029-040.png  Sample029              28"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Images</th>\n      <th>Labels</th>\n      <th>Encoded Labels</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>/train/Sample029/img029-019.png</td>\n      <td>Sample029</td>\n      <td>28</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>/train/Sample029/img029-028.png</td>\n      <td>Sample029</td>\n      <td>28</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>/train/Sample029/img029-051.png</td>\n      <td>Sample029</td>\n      <td>28</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>/train/Sample029/img029-023.png</td>\n      <td>Sample029</td>\n      <td>28</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>/train/Sample029/img029-040.png</td>\n      <td>Sample029</td>\n      <td>28</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "labelEncoder = LabelEncoder()\n",
    "data['Encoded Labels'] = labelEncoder.fit_transform(data['Labels'])\n",
    "data.head()"
   ]
  },
  {
   "source": [
    "We now create the training and validation splits of the images."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchSize = 128\n",
    "validationSplit = 0.1\n",
    "shuffleDataset = True\n",
    "randomSeed = 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetSize = len(data)\n",
    "indices = list(range(datasetSize))\n",
    "split = int(np.floor(validationSplit*datasetSize))\n",
    "if shuffleDataset:\n",
    "    np.random.seed(randomSeed)\n",
    "    np.random.shuffle(indices)\n",
    "trainIndices, validationIndices = indices[split:], indices[:split]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainSampler = SubsetRandomSampler(trainIndices)\n",
    "validationSampler = SubsetRandomSampler(validationIndices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, imageData, imagePath, transform=None):\n",
    "        self.imagePath = imagePath\n",
    "        self.imageData = imageData\n",
    "        self.transform = transform\n",
    "    def __len__(self):\n",
    "        return len(self.imageData)\n",
    "    def __getitem__(self, index):\n",
    "        imageName = os.path.join(self.imagePath, self.imageData.loc[index, 'labels'],self.imageData.loc[index,'Images'])\n",
    "        image = Image.open(imageName)\n",
    "        image = image.resize((28,28))\n",
    "        label = torch.tensor(self.imageData.loc[index, 'Encoded Labels'])\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        return image,label"
   ]
  },
  {
   "source": [
    "We now create  the custom dataset using all the images"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CustomDataset(data,'./train/',transform)"
   ]
  },
  {
   "source": [
    "We create train and validation loaders that will load batches of images for training and validation using the indices we created above"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainLoader = torch.utils.data.DataLoader(dataset, batch_size = batch_size, sampler = trainSampler)\n",
    "validationLoader = torch.utils.data.DataLoader(dataset, batch_size = batch_size, sampler = validationSampler)"
   ]
  },
  {
   "source": [
    "To visualize the images, we  first need to unormalize  them, this is performed in the function below"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def  displayImage(image):\n",
    "    image = image/2 + 0.5\n",
    "    image = image.numpy()\n",
    "    image = image.transpose(image, (1,2,0))\n",
    "    return image"
   ]
  },
  {
   "source": [
    "We now visualize some of our training images"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataIterator = iter(trainLoader)\n",
    "images, labels = dataIterator.next()\n",
    "figure, axis = plt.subplots(3,5, figsize=(16,16))\n",
    "for i, ax in enumerate(axis.flat):\n",
    "    with torch.no_grad():\n",
    "        image, label = images[i], labels[i]\n",
    "        ax.imshow(displayImage(image))\n",
    "        ax.set(title=f\"{label.item()}\")"
   ]
  },
  {
   "source": [
    "## Part 2: Embedding Network and its training"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Importing important libraries for the section"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the pytorch metric learning library comes with inbuilt methods for triplet mining and computing triplet losses between anchor, positive class and negative class\n",
    "from pytorch_metric_learning import losses, miners, distances, reducers, testers\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "source": [
    "We now define our embedding network"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EmbeddingNetwork, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3,96, kernel_size = (3,3), stride = 1, padding = 1)\n",
    "        self.conv2 = nn.Conv2d(96, 96, kernel_size = (4,4), stride = 2, padding = 1 )\n",
    "        self.conv3 = nn.Conv2d(96, 256, kernel_size = (1,1), stride = 1)\n",
    "        self.maxpooling1 = nn.MaxPool2d(kernel_size = (3,3), stride = 2, padding = 1)\n",
    "        self.fullyConnected1 = nn.Linear(256*8*8,256)\n",
    "        self.fullyConnected2 = nn.Linear(256,128)\n",
    "        self.bactchNorm1 = nn.BatchNorm2d(96)\n",
    "        self.batchNorm2 = nn.BatchNorm2d(256)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "    def forward(self,x):\n",
    "        x = self.bactchNorm1(F.relu(self.conv1(x)))\n",
    "        x = self.batchNorm1(F.relu(self.conv2(x)))\n",
    "        x = self.batchNorm2(F.relu(self.conv3(x)))\n",
    "        x = x.view(-1, 256*8*8)\n",
    "        x = self.dropout(self.fullyConnected1(x))\n",
    "        x = self.dropout(self.fullyConnected2(x))\n",
    "        x = F.normalize(x, p=2, dim=-1)\n",
    "        return x"
   ]
  },
  {
   "source": [
    "We shall now create the embedding model and print its layers"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddingNetwork = EmbeddingNetwork()\n",
    "print(embeddingNetwork)"
   ]
  },
  {
   "source": [
    "The train function below  takes this Embedding model along with the training loaded, the triplet miner and the triplet loss function to train the embedding network for a single epoch"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, lossFunction, miningFunction, device, trainLoader, optimizer, epoch):\n",
    "    print(\"Training started for Epoch: \"epoch)\n",
    "    model.train()\n",
    "    for batchIndex, (data, labels) in enumerate(trainLoader):\n",
    "        data, labels = data.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        embeddings = model(data)\n",
    "        indicesTuple = miningFunction(embeddings, labels)\n",
    "        loss = lossFunction(embeddings, labels, indicesTuple)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batchIndex%5==0:\n",
    "            print(\"Training Strats for Epoch {} Iteration {}: Loss= {}, Number of mined triplets {}\".format(epoch, batchIndex, loss, miningFunction.num_triplets))"
   ]
  },
  {
   "source": [
    "We now define the loss function, triplet miner, optimizer, and other important hyperparamters we will be using to trai the model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#distance this tells the model how to calculate the distance between the  generated embeddings\n",
    "distance = distances.CosineSimilarity()\n",
    "reducer = reducers.ThresholdReducer(low=0)\n",
    "lossFunction = losses.TripletMarginLoss(margin=0.2, distance=distance, type_of_triplets = \"semihard\")\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Training the model on: \",device)"
   ]
  },
  {
   "source": [
    "The function below uses the above function to train the embedding model for 10 epochs, we won't be saving the model at this point as we are not  yet classifying the images."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1, 11):\n",
    "    train(embeddingNetwork, lossFunction, miningFunction, device, trainLoader, optimizer, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}